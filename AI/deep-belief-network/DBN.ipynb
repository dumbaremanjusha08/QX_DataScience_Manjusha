{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbn.tensorflow import SupervisedDBNClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "5      0       0       0       0       0       0       0       0       0   \n",
       "6      7       0       0       0       0       0       0       0       0   \n",
       "7      3       0       0       0       0       0       0       0       0   \n",
       "8      5       0       0       0       0       0       0       0       0   \n",
       "9      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "5       0  ...         0         0         0         0         0         0   \n",
       "6       0  ...         0         0         0         0         0         0   \n",
       "7       0  ...         0         0         0         0         0         0   \n",
       "8       0  ...         0         0         0         0         0         0   \n",
       "9       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "5         0         0         0         0  \n",
       "6         0         0         0         0  \n",
       "7         0         0         0         0  \n",
       "8         0         0         0         0  \n",
       "9         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(digits.drop([\"label\"], axis=1))\n",
    "\n",
    "Y = np.array(digits[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SupervisedDBNClassification(hidden_layers_structure =       [256, 256],\n",
    "learning_rate_rbm=0.05,\n",
    "learning_rate=0.1,\n",
    "n_epochs_rbm=10,\n",
    "n_iter_backprop=100,\n",
    "batch_size=32,\n",
    "activation_function='relu',\n",
    "dropout_p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:127: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:143: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:149: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:150: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:178: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 400630200.377209\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 4947017220.080458\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 20375163598.945206\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 56945804051.438240\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 153781256586.098236\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 290430247065.594666\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 529605015981.712708\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 929276489408.540161\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 1528317079783.197510\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 2307532397882.337891\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 4058873401730649702466060288.000000\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 2736475313638671719684112384.000000\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 3377009134381670553943539712.000000\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 1810198918436717906393825280.000000\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 3410590177589261780410957824.000000\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 2946518500951178875615838208.000000\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 2849423694584327176493989888.000000\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 3428926241198529074717261824.000000\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 3302593197900895146607640576.000000\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 7379207645063970568083079168.000000\n",
      "[END] Pre-training step\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:338: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Sachin\\AI2019\\deep-belief-network\\dbn\\tensorflow\\models.py:357: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 0 finished \tANN training loss nan\n",
      ">> Epoch 1 finished \tANN training loss nan\n",
      ">> Epoch 2 finished \tANN training loss nan\n",
      ">> Epoch 3 finished \tANN training loss nan\n",
      ">> Epoch 4 finished \tANN training loss nan\n",
      ">> Epoch 5 finished \tANN training loss nan\n",
      ">> Epoch 6 finished \tANN training loss nan\n",
      ">> Epoch 7 finished \tANN training loss nan\n",
      ">> Epoch 8 finished \tANN training loss nan\n",
      ">> Epoch 9 finished \tANN training loss nan\n",
      ">> Epoch 10 finished \tANN training loss nan\n",
      ">> Epoch 11 finished \tANN training loss nan\n",
      ">> Epoch 12 finished \tANN training loss nan\n",
      ">> Epoch 13 finished \tANN training loss nan\n",
      ">> Epoch 14 finished \tANN training loss nan\n",
      ">> Epoch 15 finished \tANN training loss nan\n",
      ">> Epoch 16 finished \tANN training loss nan\n",
      ">> Epoch 17 finished \tANN training loss nan\n",
      ">> Epoch 18 finished \tANN training loss nan\n",
      ">> Epoch 19 finished \tANN training loss nan\n",
      ">> Epoch 20 finished \tANN training loss nan\n",
      ">> Epoch 21 finished \tANN training loss nan\n",
      ">> Epoch 22 finished \tANN training loss nan\n",
      ">> Epoch 23 finished \tANN training loss nan\n",
      ">> Epoch 24 finished \tANN training loss nan\n",
      ">> Epoch 25 finished \tANN training loss nan\n",
      ">> Epoch 26 finished \tANN training loss nan\n",
      ">> Epoch 27 finished \tANN training loss nan\n",
      ">> Epoch 28 finished \tANN training loss nan\n",
      ">> Epoch 29 finished \tANN training loss nan\n",
      ">> Epoch 30 finished \tANN training loss nan\n",
      ">> Epoch 31 finished \tANN training loss nan\n",
      ">> Epoch 32 finished \tANN training loss nan\n",
      ">> Epoch 33 finished \tANN training loss nan\n",
      ">> Epoch 34 finished \tANN training loss nan\n",
      ">> Epoch 35 finished \tANN training loss nan\n",
      ">> Epoch 36 finished \tANN training loss nan\n",
      ">> Epoch 37 finished \tANN training loss nan\n",
      ">> Epoch 38 finished \tANN training loss nan\n",
      ">> Epoch 39 finished \tANN training loss nan\n",
      ">> Epoch 40 finished \tANN training loss nan\n",
      ">> Epoch 41 finished \tANN training loss nan\n",
      ">> Epoch 42 finished \tANN training loss nan\n",
      ">> Epoch 43 finished \tANN training loss nan\n",
      ">> Epoch 44 finished \tANN training loss nan\n",
      ">> Epoch 45 finished \tANN training loss nan\n",
      ">> Epoch 46 finished \tANN training loss nan\n",
      ">> Epoch 47 finished \tANN training loss nan\n",
      ">> Epoch 48 finished \tANN training loss nan\n",
      ">> Epoch 49 finished \tANN training loss nan\n",
      ">> Epoch 50 finished \tANN training loss nan\n",
      ">> Epoch 51 finished \tANN training loss nan\n",
      ">> Epoch 52 finished \tANN training loss nan\n",
      ">> Epoch 53 finished \tANN training loss nan\n",
      ">> Epoch 54 finished \tANN training loss nan\n",
      ">> Epoch 55 finished \tANN training loss nan\n",
      ">> Epoch 56 finished \tANN training loss nan\n",
      ">> Epoch 57 finished \tANN training loss nan\n",
      ">> Epoch 58 finished \tANN training loss nan\n",
      ">> Epoch 59 finished \tANN training loss nan\n",
      ">> Epoch 60 finished \tANN training loss nan\n",
      ">> Epoch 61 finished \tANN training loss nan\n",
      ">> Epoch 62 finished \tANN training loss nan\n",
      ">> Epoch 63 finished \tANN training loss nan\n",
      ">> Epoch 64 finished \tANN training loss nan\n",
      ">> Epoch 65 finished \tANN training loss nan\n",
      ">> Epoch 66 finished \tANN training loss nan\n",
      ">> Epoch 67 finished \tANN training loss nan\n",
      ">> Epoch 68 finished \tANN training loss nan\n",
      ">> Epoch 69 finished \tANN training loss nan\n",
      ">> Epoch 70 finished \tANN training loss nan\n",
      ">> Epoch 71 finished \tANN training loss nan\n",
      ">> Epoch 72 finished \tANN training loss nan\n",
      ">> Epoch 73 finished \tANN training loss nan\n",
      ">> Epoch 74 finished \tANN training loss nan\n",
      ">> Epoch 75 finished \tANN training loss nan\n",
      ">> Epoch 76 finished \tANN training loss nan\n",
      ">> Epoch 77 finished \tANN training loss nan\n",
      ">> Epoch 78 finished \tANN training loss nan\n",
      ">> Epoch 79 finished \tANN training loss nan\n",
      ">> Epoch 80 finished \tANN training loss nan\n",
      ">> Epoch 81 finished \tANN training loss nan\n",
      ">> Epoch 82 finished \tANN training loss nan\n",
      ">> Epoch 83 finished \tANN training loss nan\n",
      ">> Epoch 84 finished \tANN training loss nan\n",
      ">> Epoch 85 finished \tANN training loss nan\n",
      ">> Epoch 86 finished \tANN training loss nan\n",
      ">> Epoch 87 finished \tANN training loss nan\n",
      ">> Epoch 88 finished \tANN training loss nan\n",
      ">> Epoch 89 finished \tANN training loss nan\n",
      ">> Epoch 90 finished \tANN training loss nan\n",
      ">> Epoch 91 finished \tANN training loss nan\n",
      ">> Epoch 92 finished \tANN training loss nan\n",
      ">> Epoch 93 finished \tANN training loss nan\n",
      ">> Epoch 94 finished \tANN training loss nan\n",
      ">> Epoch 95 finished \tANN training loss nan\n",
      ">> Epoch 96 finished \tANN training loss nan\n",
      ">> Epoch 97 finished \tANN training loss nan\n",
      ">> Epoch 98 finished \tANN training loss nan\n",
      ">> Epoch 99 finished \tANN training loss nan\n",
      "[END] Fine tuning step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SupervisedDBNClassification(batch_size=32, dropout_p=0.2,\n",
       "                            idx_to_label_map={0: 6, 1: 4, 2: 2, 3: 3, 4: 1,\n",
       "                                              5: 8, 6: 5, 7: 7, 8: 9, 9: 0},\n",
       "                            l2_regularization=1.0,\n",
       "                            label_to_idx_map={0: 9, 1: 4, 2: 2, 3: 3, 4: 1,\n",
       "                                              5: 6, 6: 0, 7: 7, 8: 5, 9: 8},\n",
       "                            learning_rate=0.1, n_iter_backprop=100,\n",
       "                            verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Accuracy: 0.100119\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "print('Done.\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
