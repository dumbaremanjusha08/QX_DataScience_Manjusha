{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "\n",
    "datasets = pd.read_csv('50_Startups.csv')\n",
    "X = datasets.iloc[:, :-1].values\n",
    "Y = datasets.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,\n",
       "       156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,\n",
       "       141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,\n",
       "       124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,\n",
       "       108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,\n",
       "        99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,\n",
       "        90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,\n",
       "        71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,\n",
       "        35673.41,  14681.4 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "        1.1059411e+05, 2.2916095e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "        9.1790610e+04, 2.4974455e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "        1.2278275e+05, 3.0331926e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "        1.2786455e+05, 3.5318381e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "        1.8264556e+05, 1.1814820e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "        1.5270192e+05, 8.8218230e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "        6.5947930e+04, 1.8526510e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "        8.4710770e+04, 1.6447071e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis creation\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\abhis creation\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       ...,\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Multiple Linear Regression in the Training set\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "\n",
    "Y_Pred = regressor.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201181.70644062,   8642.38328958,  77587.21842714,   9734.3803939 ,\n",
       "        98210.69677375, 159830.04917329,  -5437.50868903, 151590.23401526,\n",
       "       119339.7823403 ,  68741.30464076])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "\n",
    "import statsmodels.regression.linear_model as sm\n",
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>  -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>  0.2284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 01 Dec 2019</td> <th>  Prob (F-statistic):</th>           <td> 0.797</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:18:49</td>     <th>  Log-Likelihood:    </th>          <td> -655.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th>          <td>   1314.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th>          <td>   1318.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td> 6.493e+04</td> <td> 1.21e+05</td> <td>    0.538</td> <td> 0.593</td> <td>-1.78e+05</td> <td> 3.08e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td> 4.949e+04</td> <td> 1.21e+05</td> <td>    0.410</td> <td> 0.684</td> <td>-1.93e+05</td> <td> 2.92e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.232</td> <th>  Durbin-Watson:     </th> <td>   0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.328</td> <th>  Jarque-Bera (JB):  </th> <td>   1.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.393</td> <th>  Prob(JB):          </th> <td>   0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.279</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.009\n",
       "Model:                            OLS   Adj. R-squared (uncentered):             -0.032\n",
       "Method:                 Least Squares   F-statistic:                             0.2284\n",
       "Date:                Sun, 01 Dec 2019   Prob (F-statistic):                       0.797\n",
       "Time:                        14:18:49   Log-Likelihood:                         -655.02\n",
       "No. Observations:                  50   AIC:                                      1314.\n",
       "Df Residuals:                      48   BIC:                                      1318.\n",
       "Df Model:                           2                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1          6.493e+04   1.21e+05      0.538      0.593   -1.78e+05    3.08e+05\n",
       "x2          4.949e+04   1.21e+05      0.410      0.684   -1.93e+05    2.92e+05\n",
       "==============================================================================\n",
       "Omnibus:                        2.232   Durbin-Watson:                   0.011\n",
       "Prob(Omnibus):                  0.328   Jarque-Bera (JB):                1.452\n",
       "Skew:                          -0.393   Prob(JB):                        0.484\n",
       "Kurtosis:                       3.279   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Optimal = X[:, [4,5]]\n",
    "regressor_OLS = sm.OLS(endog = Y, exog = X_Optimal).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Multiple Linear Regression in the Optimal Training set\n",
    "\n",
    "X_Optimal_Train, X_Optimal_Test = train_test_split(X_Optimal,test_size = 0.2, random_state = 0)\n",
    "regressor.fit(X_Optimal_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Optimal Test set results\n",
    "\n",
    "Y_Optimal_Pred = regressor.predict(X_Optimal_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112195.81736842, 112195.81736842, 112195.81736842, 112195.81736842,\n",
       "       112195.81736842, 112195.81736842, 112195.81736842, 112195.81736842,\n",
       "       112195.81736842, 112195.81736842])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Optimal_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25a7d6b5688>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_Test, Y_Optimal_Pred, color = 'red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
